---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s-labs/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: open-webui
spec:
  chartRef:
    kind: OCIRepository
    name: open-webui
  interval: 15m
  values:
    controllers:
      open-webui:
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          app:
            image:
              repository: ghcr.io/open-webui/open-webui
              tag: v0.8.5-cuda@sha256:27c689cbda5481d797b35125a1c58f9060df69d23bdad3f7c1612a4ec9185235
            env:
              CORS_ALLOW_ORIGIN: https://chat.beholdenkey.dev
              ENABLE_OPENAI_API: False
              ENABLE_OLLAMA_API: True
              # Open-webui settings
              OLLAMA_BASE_URL: http://ollama.llm.svc.cluster.local:11434
              ENABLE_RAG_WEB_SEARCH: true
              ENABLE_SEARCH_QUERY: true
              RAG_WEB_SEARCH_ENGINE: searxng
              SEARXNG_QUERY_URL: http://searxng:8080/search?q=<query>
              ENABLE_WEBSOCKET_SUPPORT: "true"
              WEBSOCKET_MANAGER: "redis"
              WEBSOCKET_REDIS_URL: "redis://dragonfly.database.svc.cluster.local:6379"
              THREAD_POOL_SIZE: 10
              GLOBAL_LOG_LEVEL: DEBUG
              MODELS_CACHE_TTL: 300
              TZ: America/New_York
            envFrom:
              - secretRef:
                  name: open-webui
            ports:
              - containerPort: 8080
                name: http
            probes:
              liveness: &probes
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health
                    port: http
              readiness: *probes
              startup:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health
                    port: http
                  failureThreshold: 60
            resources:
              limits:
                nvidia.com/gpu: 1
        pod:
          nodeSelector:
            nvidia.com/gpu.present: "true"
          runtimeClassName: nvidia
    service:
      app:
        ports:
          http:
            port: 8080
    route:
      app:
        hostnames:
          - "chat.beholdenkey.dev"
        parentRefs:
          - name: envoy-internal
            namespace: network
    persistence:
      config:
        enabled: true
        existingClaim: "{{ .Release.Name }}"
        globalMounts:
          - path: /app/backend/data
