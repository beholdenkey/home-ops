---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s-labs/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: open-webui
spec:
  chartRef:
    kind: OCIRepository
    name: open-webui
  interval: 15m
  values:
    controllers:
      open-webui:
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          app:
            image:
              repository: ghcr.io/open-webui/open-webui
              tag: v0.8.6-cuda@sha256:7dcff2df54b4912dfd372a668a1236ac3f337525aff4103c3fa6fca9c0317190
            env:
              CORS_ALLOW_ORIGIN: https://chat.beholdenkey.dev
              ENABLE_OPENAI_API: False
              ENABLE_OLLAMA_API: True
              OLLAMA_BASE_URL: http://ollama-windows.llm.svc.cluster.local:11434
              ENABLE_SEARCH_QUERY: true
              ENABLE_RAG_WEB_SEARCH: true
              RAG_WEB_SEARCH_ENGINE: "searxng"
              RAG_WEB_SEARCH_RESULT_COUNT: 3
              RAG_WEB_SEARCH_CONCURRENT_REQUESTS: 10
              SEARXNG_QUERY_URL: "http://searxng.llm.svc.cluster.local:8080/search?q={query}&format=json"
              ENABLE_WEBSOCKET_SUPPORT: "true"
              WEBSOCKET_MANAGER: "redis"
              WEBSOCKET_REDIS_URL: "redis://dragonfly.database.svc.cluster.local:6379/1"
              THREAD_POOL_SIZE: 10
              GLOBAL_LOG_LEVEL: DEBUG
              MODELS_CACHE_TTL: 300
              TZ: America/New_York
            envFrom:
              - secretRef:
                  name: open-webui
            ports:
              - containerPort: 8080
                name: http
            probes:
              liveness: &probes
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health
                    port: http
              readiness: *probes
              startup:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health
                    port: http
                  failureThreshold: 60
            resources:
              limits:
                nvidia.com/gpu: 1
            securityContext:
              allowPrivilegeEscalation: false
              capabilities: {drop: ["ALL"]}
              readOnlyRootFilesystem: true
        pod:
          nodeSelector:
            nvidia.com/gpu.present: "true"
          runtimeClassName: nvidia
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            runAsGroup: 1000
            fsGroup: 1000
            fsGroupChangePolicy: OnRootMismatch
    service:
      app:
        ports:
          http:
            port: 8080
    route:
      app:
        hostnames:
          - "chat.beholdenkey.dev"
        parentRefs:
          - name: envoy-internal
            namespace: network
    persistence:
      config:
        enabled: true
        existingClaim: "{{ .Release.Name }}"
        globalMounts:
          - path: /app/backend/data
      run:
        type: emptyDir
        medium: Memory
        sizeLimit: 128Mi
      tmp:
        type: emptyDir
        medium: Memory
        sizeLimit: 128Mi
